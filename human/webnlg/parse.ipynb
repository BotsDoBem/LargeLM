{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json\n",
    "import csv\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create directory to save human evaluation sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('human'):\n",
    "    os.mkdir('human')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WebNLG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find testset of human evaluation in the first challenge\n",
    "\n",
    "path = os.path.join('results', 'webnlg_t5', 'result.json')\n",
    "data = json.load(open(path))\n",
    "\n",
    "with open('human/webnlg/sample_ids.txt') as f:\n",
    "    sample_ids = f.read().split()\n",
    "\n",
    "tree = ET.parse('human/webnlg/testnolex.xml')\n",
    "root = tree.getroot().find('entries')\n",
    "\n",
    "idxs = []\n",
    "for entry in root:\n",
    "    category = entry.attrib['category']\n",
    "    eid = entry.attrib['eid'].replace('Id', '')\n",
    "    if eid in sample_ids:\n",
    "        modifiedtripleset = []\n",
    "        for triple in entry.find('modifiedtripleset').findall('mtriple'):\n",
    "            subj, pred, obj = triple.text.split(' | ')\n",
    "            modifiedtripleset.append({\n",
    "                'subject': subj,\n",
    "                'property': pred,\n",
    "                'object': obj\n",
    "            })\n",
    "        triples = []\n",
    "        for triple in sorted(modifiedtripleset, key=lambda x: (x['property'], x['subject'], x['object'])):\n",
    "            subj, pred, obj = triple['subject'], triple['property'], triple['object']\n",
    "            str_triple = ' '.join(['<subject>', subj, '<predicate>', pred, '<object>', obj])\n",
    "            triples.append(str_triple)\n",
    "        triples = ' <triple> '.join(triples)\n",
    "        inp = ' '.join([category, triples])\n",
    "        \n",
    "        for i, row in enumerate(data):\n",
    "            if row['intent'] == inp:\n",
    "                idxs.append(i)\n",
    "                \n",
    "path = os.path.join('human/webnlg', 'idxs.json')\n",
    "json.dump(idxs, open(path, 'w'), separators=(',', ':'), sort_keys=True, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "for fdir in os.listdir('results'):\n",
    "    if 'webnlg' in fdir:\n",
    "        path = os.path.join('results', fdir, 'result.json')\n",
    "        result = json.load(open(path))\n",
    "        \n",
    "        for idx in idxs:\n",
    "            f = data[idx]\n",
    "            output.append({\n",
    "                'idx': idx,\n",
    "                'intent': ' <triple>\\n '.join(f['intent'].split(' <triple> ')),\n",
    "                'hyp': f['hyp'].strip(),\n",
    "                'ref': f['refs'][0],\n",
    "                'domain': fdir\n",
    "            })\n",
    "            \n",
    "for idx in idxs:\n",
    "    f = data[idx]\n",
    "    output.append({\n",
    "        'idx': idx,\n",
    "        'intent': ' <triple>\\n '.join(f['intent'].split(' <triple> ')),\n",
    "        'hyp': f['refs'][0],\n",
    "        'ref': f['refs'][0],\n",
    "        'domain': 'gold'\n",
    "    })\n",
    "\n",
    "shuffle(output)\n",
    "# save idxs\n",
    "fdir = os.path.join('human', 'webnlg')\n",
    "path = os.path.join(fdir, 'result.json')\n",
    "json.dump(output, open(path, 'w'), separators=(',', ':'), sort_keys=True, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdir = os.path.join('human', 'webnlg')\n",
    "path = os.path.join(fdir, 'annotation.csv')\n",
    "\n",
    "header = [\"MR\", \"Reference\", \"Hypothesis\", \\\n",
    "          \"Incorrect Number\", \"Incorrect Named Entity\", \\\n",
    "          \"Incorrect Word\", \"Context Error\", \"Not checkable\", \"Other\", \"Fluency\"]\n",
    "\n",
    "with open(path, 'w') as f:\n",
    "    writer = csv.writer(f, delimiter=';', quotechar='\\\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    writer.writerow(header)\n",
    "    \n",
    "    for row in output:\n",
    "        writer.writerow([row['intent'], row['ref'], row['hyp']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
